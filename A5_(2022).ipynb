{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkhfring/parallel-c/blob/main/A5_(2022).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JrIevO5mEoV"
      },
      "source": [
        "# A5 (10 Marks)\n",
        "---\n",
        "**Focus**: CUDA(A, B, C) - Introduction (warming up!!)\n",
        "\n",
        "Â© Dr. Abdallah Mohamed\n",
        "\n",
        "This version of the assignment is the Google Colab version and takes advantage of the free Cloud GPUs offered through the platform. Colab Notebooks (you're reading one right now!) are typically designed to run Python code, however, we'll be modifying them in such a way that we can run CUDA code (as discussed in the lectures) on the GPU.\n",
        "\n",
        "Please note that code can be written and run directly within this assignment. Lastly, keep in mind that anytime your runtime disconnects or is restarted **you must re-run the Notebook Setup code block**. This applies to all CUDA assignments done using Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hd9jjAb30WQ"
      },
      "source": [
        "## Notebook Setup: CUDA Compilation\n",
        "\n",
        "To enable CUDA code compilation on Colab Notebooks, we'll employ use of the NVCC4Jupyter plugin (source code/documentation available [here](https://github.com/engasa/nvcc4jupyter)). This plugin effectively turns any Colab Notebook code block that includes `%%cu` into compilable/runnable CUDA code.\n",
        "\n",
        "To download/install/enable NVCC4Jupyter, please run the following code block. **Running this block is required anytime you connect/restart/reconnect to an instance.** To run a code block, mouse over it and click the play button on left side."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R3aMhww6WKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7eb029-d708-4561-e928-25594432d811"
      },
      "source": [
        "# Run the following to configure your notebook for CUDA code\n",
        "!pip install git+https://github.com/engasa/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/engasa/nvcc4jupyter.git\n",
            "  Cloning https://github.com/engasa/nvcc4jupyter.git to /tmp/pip-req-build-1bmrb3b6\n",
            "  Running command git clone -q https://github.com/engasa/nvcc4jupyter.git /tmp/pip-req-build-1bmrb3b6\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4407 sha256=243b07a5c1b844a38a9f829622f345e6e51a9073ce9e7efa68d9112d8aa7f0a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mlanb7lt/wheels/d2/a3/04/ef659d715dcdd196d998813ca085af3cab3df66f4bb27576b5\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see some output when you click the play button. Wait until the code block is finished running (this is indicated when the stop button goes away). The last couple lines of output should look something like the following:\n",
        "\n",
        "```\n",
        "created output directory at /content/src\n",
        "Out bin /content/result.out\n",
        "```"
      ],
      "metadata": {
        "id": "shMOxQ6gKNV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Setup: GPU Runtime\n",
        "\n",
        "Before writing/running any CUDA code, we need to ensure Colab is provisioning a Cloud GPU for us. To do this, click on the \"Runtime\" menu item in the top bar and select the \"Change runtime type\" option. Select \"GPU\" from the list of Hardware accelerators and click \"Ok\". \n",
        "\n",
        "You can also check if GPU has been allocated. Colab notebooks without a GPU technically have access to NVCC and will compile and execute CPU/Host code, however, GPU/Device code will silently fail. To prevent such situations, this code will warn the user."
      ],
      "metadata": {
        "id": "X579drLVkfJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include \"device_launch_parameters.h\"\n",
        "int main() {\n",
        "  int count;\n",
        "  cudaGetDeviceCount(&count);\n",
        "  if (count <= 0 || count > 100)  printf(\"WARNING<-: NO GPU DETECTED ON THIS COLLABORATE INSTANCE. YOU SHOULD CHANGE THE RUNTIME TYPE.\\n\");\n",
        "  else                            printf(\"GPU ENABLED. - You are ready to start\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPZl86qfkpf7",
        "outputId": "f5c276ea-55bf-4235-e00c-133ebf7f9dd5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU ENABLED. - You are ready to start\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *If the output above is ```GPU ENABLED - You are ready to start```*\n",
        "### *then you're ready to begin the assignment!*"
      ],
      "metadata": {
        "id": "5p6rO_47lArS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6I7-EHCnSB_"
      },
      "source": [
        "# Question 1. [+3] \n",
        "\n",
        "Querying your GPU: In this question, you will run simple query code to discover the properties and limits of your Colab-provisioned NVIDIA card. Run the code block below, then capture your answers and **submit** them as an image file named A5_Q1.png.\n",
        "\n",
        "**Note:** See below that `%%cu` needs to be added to let Colab know that the code block is CUDA code.\n",
        "\n",
        "*Marking Guide: +3 for a screenshot with the required info*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTKcmsc8_khE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1787c971-5b42-4cdd-f434-78f8809320c0"
      },
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaDeviceProp prop;\n",
        "    int count;\n",
        "    cudaGetDeviceCount(&count);\n",
        "    for (int i = 0; i < count; i++)\n",
        "    {\n",
        "        cudaGetDeviceProperties(&prop, i);\n",
        "        printf(\"----- General Information for device %d ---\\n\", i);\n",
        "        printf(\"Name:\t%s\\n\", prop.name);\n",
        "        printf(\"Compute capability:\t%d.%d\\n\", prop.major, prop.minor);\n",
        "        printf(\"Clock rate:\t%d\\n\", prop.clockRate);\n",
        "        printf(\"Device copy overlap:\t\");\n",
        "        printf(prop.deviceOverlap ? \"Enabled\\n\" : \"Disabled\\n\");\n",
        "        printf(\"Kernel execution timeout: \");\n",
        "        printf(prop.kernelExecTimeoutEnabled ? \"Enabled\\n\" : \"Disabled\\n\");\n",
        "        printf(\"----- Memory Information for device %d ---\\n\", i);\n",
        "        printf(\"Total global mem:\t%lu\\n\", prop.totalGlobalMem);\n",
        "        printf(\"Total constant Mem:\t%ld\\n\", prop.totalConstMem);\n",
        "        printf(\"Max mem pitch:\t%ld\\n\", prop.memPitch);\n",
        "        printf(\"Texture Alignment:\t%ld\\n\", prop.textureAlignment);\n",
        "        printf(\"----- MP Information for device %d ---\\n\", i);\n",
        "        printf(\"Multiprocessor count:\t%d\\n\", prop.multiProcessorCount);\n",
        "        printf(\"Shared mem per mp:\t%ld\\n\", prop.sharedMemPerBlock);\n",
        "        printf(\"Registers per mp:\t%d\\n\", prop.regsPerBlock);\n",
        "        printf(\"Threads in warp:\t%d\\n\", prop.warpSize);\n",
        "        printf(\"Max threads per block:\t%d\\n\", prop.maxThreadsPerBlock);\n",
        "        printf(\"Max thread dimensions:\t(%d, %d, %d)\\n\",\n",
        "               prop.maxThreadsDim[0], prop.maxThreadsDim[1], prop.maxThreadsDim[2]);\n",
        "        printf(\"Max grid dimensions:\t(%d, %d, %d)\\n\", prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2]);\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- General Information for device 0 ---\n",
            "Name:\tTesla T4\n",
            "Compute capability:\t7.5\n",
            "Clock rate:\t1590000\n",
            "Device copy overlap:\tEnabled\n",
            "Kernel execution timeout: Disabled\n",
            "----- Memory Information for device 0 ---\n",
            "Total global mem:\t15843721216\n",
            "Total constant Mem:\t65536\n",
            "Max mem pitch:\t2147483647\n",
            "Texture Alignment:\t512\n",
            "----- MP Information for device 0 ---\n",
            "Multiprocessor count:\t40\n",
            "Shared mem per mp:\t49152\n",
            "Registers per mp:\t65536\n",
            "Threads in warp:\t32\n",
            "Max threads per block:\t1024\n",
            "Max thread dimensions:\t(1024, 1024, 64)\n",
            "Max grid dimensions:\t(2147483647, 65535, 65535)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z_NlOUrATP6"
      },
      "source": [
        "# Question 2. [+7]\n",
        "\n",
        "**Simple CUDA code:** consider this loop for initializing an array **a**:\n",
        "\n",
        "```c\n",
        "const int n = 10000000 // 10 million\n",
        "for (i = 0; i < n; i++)\n",
        "    a[i] = (double)i / n;\n",
        "```\n",
        "\n",
        "Submit:\n",
        "\n",
        "1.   The serial implementation running on the CPU.\n",
        "2.   The CUDA implementation (1 thread per array element).\n",
        "\n",
        "In both cases, add code to print the first and last 5 elements of the array to verify your code.\n",
        "\n",
        "*Note that you need to use the placeholder %.7f to print 7 digits after the decimal point.*\n",
        "\n",
        "***Sample output:***\n",
        "\n",
        "```c\n",
        "a[0]: 0.0000000\n",
        "a[1]: 0.0000001\n",
        "a[2]: 0.0000002\n",
        "a[3]: 0.0000003\n",
        "a[4]: 0.0000004\n",
        "...\n",
        "a[9999995]: 0.9999995 \n",
        "a[9999996]: 0.9999996 \n",
        "a[9999997]: 0.9999997 \n",
        "a[9999998]: 0.9999998 \n",
        "a[9999999]: 0.9999999\n",
        "```\n",
        "\n",
        "***Marking Guide:***\n",
        "\n",
        "+2 for measuring the time of the parallel and serial code \n",
        "\n",
        "+2 for the kernel function\n",
        "\n",
        "+3 for launch configuration and properly calling the kernel\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyqpuDM2CX6K"
      },
      "source": [
        "### CPU Implementation\n",
        "\n",
        "Please code and run your CPU implementation in the code block below. When submitting your assignment, please copy the code block into a text/c file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpli5URsCtPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0793ac7e-0074-43eb-d21d-13a8a8c9c5b0"
      },
      "source": [
        "%%cu\n",
        "\n",
        "// CPU Implementation goes here!\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "\n",
        "void vector_init(double *arr, int size);\n",
        "int main(){\n",
        "    clock_t start, end;\n",
        "    const int n = 10000000;\n",
        "    double *a = (double*) malloc(n * sizeof(double));\n",
        "    if (NULL == a){\n",
        "        printf(\"enable to allocate memory\");\n",
        "        exit(0);\n",
        "    }\n",
        "    start = clock();\n",
        "    vector_init(a, n);\n",
        "    end = clock();\n",
        "    double total_time = ((double) (end - start)) / CLOCKS_PER_SEC;\n",
        "    printf(\"The total time to execute the serial code is %.3f \\n\", total_time);\n",
        "    for (int i=0; i<5; i++){\n",
        "        printf(\"a[%d]: %.7f \\n\", i, a[i]);\n",
        "    }\n",
        "    printf(\"....\\n\");\n",
        "    for (int i=n-5; i<n; i++){\n",
        "        printf(\"a[%d]: %.7f \\n\", i, a[i]);\n",
        "    }\n",
        "\n",
        "}\n",
        "void vector_init(double *arr, int size){\n",
        "    for(int i=0; i<size; i++){\n",
        "        arr[i] = (double) i/size;\n",
        "    }\n",
        "}"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total time to execute the serial code is 0.092 \n",
            "a[0]: 0.0000000 \n",
            "a[1]: 0.0000001 \n",
            "a[2]: 0.0000002 \n",
            "a[3]: 0.0000003 \n",
            "a[4]: 0.0000004 \n",
            "....\n",
            "a[9999995]: 0.9999995 \n",
            "a[9999996]: 0.9999996 \n",
            "a[9999997]: 0.9999997 \n",
            "a[9999998]: 0.9999998 \n",
            "a[9999999]: 0.9999999 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0froFiPCwgJ"
      },
      "source": [
        "### CUDA Implementation\n",
        "\n",
        "Please code and run your CUDA implementation in the code block below. When submitting your assignment, please copy the code block into a text/cu file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHHRVWZNC1Iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac15446f-812a-440f-8afe-7b70edb5c8db"
      },
      "source": [
        "%%cu\n",
        "\n",
        "// CUDA Implementation goes here!\n",
        "#include <stdio.h>\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "#define MaxThreads 1024\n",
        "#define CHK(call) {cudaError_t err = call; if (err != cudaSuccess) { printf(\"Error%d: %s:%d\\n\",err,__FILE__,__LINE__); printf(cudaGetErrorString(err)); cudaDeviceReset(); exit(1);}}\n",
        "\n",
        "\n",
        "__global__ void vector_init(double *arr, int size);\n",
        "int main(){\n",
        "    clock_t start, end;\n",
        "    double *a, *d_a;\n",
        "    const int n = 10000000;\n",
        "    int block_number = (int) n/MaxThreads + 1;\n",
        "    a = (double*) malloc(n * sizeof(double));\n",
        "    if (NULL == a){\n",
        "        printf(\"enable to allocate memory\");\n",
        "        exit(0);\n",
        "    }\n",
        "    CHK(cudaMalloc(&d_a, n *sizeof(double));)\n",
        "    start = clock();\n",
        "    vector_init<<<block_number, MaxThreads>>>(d_a, n);\n",
        "    cudaMemcpy(a, d_a, n * sizeof(double), cudaMemcpyDeviceToHost);\n",
        "    end = clock();\n",
        "    double total_time = ((double) (end - start)) / CLOCKS_PER_SEC; \n",
        "    printf(\"The total time to execute the serial code is %.3f \\n\", total_time);\n",
        "    for (int i=0; i<5; i++){\n",
        "        printf(\"a[%d]: %.7f \\n\", i, a[i]);\n",
        "    }\n",
        "    printf(\"....\\n\");\n",
        "    for (int i=n-5; i<n; i++){\n",
        "        printf(\"a[%d]: %.7f \\n\", i, a[i]);\n",
        "    }\n",
        "\n",
        "\n",
        "}\n",
        "__global__ void vector_init(double *arr, int size){\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if(i < size){\n",
        "        double val = (double) i / size;\n",
        "        arr[i] = val;\n",
        "    }\n",
        "}"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total time to execute the serial code is 0.055 \n",
            "a[0]: 0.0000000 \n",
            "a[1]: 0.0000001 \n",
            "a[2]: 0.0000002 \n",
            "a[3]: 0.0000003 \n",
            "a[4]: 0.0000004 \n",
            "....\n",
            "a[9999995]: 0.9999995 \n",
            "a[9999996]: 0.9999996 \n",
            "a[9999997]: 0.9999997 \n",
            "a[9999998]: 0.9999998 \n",
            "a[9999999]: 0.9999999 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYLlFNpdDOOS"
      },
      "source": [
        "---\n",
        "\n",
        "**Submission instructions**\n",
        "\n",
        "For this assignment, you need to do the following:\n",
        "\n",
        "1. Compress the PNG file from Q1 and the source code file (i.e. the .cu/c files, not the whole notebook) from Q2 into one zip folder and give a name to the zipped file that matches your ID (e.g., 1234567.zip).\n",
        "\n",
        "2. Submit the zipped file to Canvas.\n",
        "\n",
        "Note that you can resubmit an assignment, but the new submission overwrites the old submission and receives a new timestamp."
      ]
    }
  ]
}